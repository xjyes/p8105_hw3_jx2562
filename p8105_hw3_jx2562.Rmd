---
title: "p8105_hx3_jx562"
author: "Jingyi"
date: "2023-10-11"
output: github_document
---

```{r, message=F}
library(tidyverse)
```


## Problem 1

This problem aims to explore `instacart` data.

First, we loaded the data `instacart`.

```{r}
library(p8105.datasets)
data("instacart")
```

The data `instacart` has features as described below.

*   The data has `r ncol(instacart)` observations and `r nrow(instacart)` variables.
*   The data has variables named `r colnames(instacart)`.
*   There are `r length(unique(instacart$aisle))` diffrent aisles, whose `aisle_id` range from `r min(instacart$aisle_id)` to `r max(instacart$aisle_id)`. 
*   There are `r length(unique(instacart$product_name))` different product.
*   Overall, the `order_number` ranges from `r min(instacart$order_number)` to `r max(instacart$order_number)` with a mean `r round(mean(instacart$order_number), 2)`
*   An example of the observations of the data is demonstrated below.

```{r}
head(instacart, 3)
```

Then, we need to answer a few questions regarding the dataset.

1.    *How many aisles are there, and which aisles are the most items ordered from?*

*   There are `r length(unique(instacart$aisle))` different aisles. 

```{r}
aisle_order = instacart |>
  group_by(aisle) |>
  summarize(order_number_aisle = sum(order_number)) |>
  arrange(desc(order_number_aisle))
```
*   The aisle where most items are ordered from and the number of order are `r head(aisle_order, 1)`.

2.    *Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. *

```{r}
aisle_order_10000 = instacart |>
  group_by(aisle_id) |>
  summarize(order_number_aisle = sum(order_number)) |>
  filter(order_number_aisle > 10000) |>
  mutate(aisle_id = as.factor(aisle_id))

ggplot(aisle_order_10000, aes(x = aisle_id, y = order_number_aisle)) +
  geom_bar(stat = "identity", fill = "steelblue",  width = 0.5) +
  labs(x = "Aisle ID", y = "Total Order Count", title = "Total Orders by Aisle (Aisles with > 10,000 Orders)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 60, size = 6)) +
  scale_x_discrete(breaks = aisle_order_10000$aisle_id[1:nrow(aisle_order_10000) %% 3 == 0])
```
*   Given the aisle id, we can look up to the exact aisle name. There are `r nrow(aisle_order_10000)` out of `r nrow(aisle_order)` which has an order number larger than 10000. The aisles with top 5 total order number count are `r aisle_order$aisle[1:5]`.

3.    *Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.*

```{r}
aisle_times = instacart |>
  group_by(aisle) |>
  summarize(order_times = n()) |>
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) 
knitr::kable(aisle_times)
```

*   The number of times ordered is obtained by counting the number of order in each aisle for the three types of aisles. It shows that `packaged vegetables fruits` has the most order times.

4. *Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.*


```{r, warning=F}
product_hour = instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_order_hour = round(mean(order_hour_of_day),2)) |>
  pivot_wider(names_from = order_dow, values_from = mean_order_hour) 
colnames(product_hour)[2:8] = c("Sun","Mon","Tue","Wed","Thu","Fri","Sat")
knitr::kable(product_hour)
```
*   The table shows the mean hour of the day at which the two product are ordered in terms of each day of the week. 


## Problem 2

This problem aims to explore `BRFSS` data.

First, we loaded the data `BRFSS`.

```{r}
library(p8105.datasets)
data("brfss_smart2010")
```

Do some data cleaning regarding to the dataset.

```{r}
brfss_clean = brfss_smart2010 |>
  janitor::clean_names() |>
  filter(topic == "Overall Health") |>
  filter(response %in% c("Poor","Fair","Good", "Very good","Excellent")) |>
  mutate(response = factor(response, levels = c("Poor","Fair","Good", "Very good","Excellent"), ordered = T))
```

Then, we are going to answer some questions regarding to the data set.

1.    *In 2002, which states were observed at 7 or more locations? What about in 2010?*

```{r, warning=F}
state_obs_2002 = brfss_clean |>
  filter(year == 2002) |>
  group_by(locationabbr, locationdesc) |>
  summarise(locationdesc_count = n()) |>
  group_by(locationabbr) |>
  summarise(location_in_state = n())

state_obs_2010 = brfss_clean |>
  filter(year == 2010) |>
  group_by(locationabbr, locationdesc) |>
  summarise(locationdesc_count = n()) |>
  group_by(locationabbr) |>
  summarise(location_in_state = n())
```

*   The above datasets give the count number of different locations where a state was observed in 2002 or 2010. In 2002, `r state_obs_2002 |> filter(location_in_state >= 7) |> pull(locationabbr)` states were observed at 7 or more locations. In 2010, `r state_obs_2010 |> filter(location_in_state >= 7) |> pull(locationabbr)` states were observed at 7 or more locations.

2.    *Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state.*

```{r}
state_value = brfss_clean |>
  filter(response == "Excellent") |>
  group_by(year, locationabbr) |>
  summarise(mean_value = mean(data_value)) |>
  select(state = locationabbr, everything())
```

Make the "spaghetti" plot.

```{r, warning=F}
ggplot(state_value, aes(x = year, y = mean_value, color = state, group = state)) +
  geom_line() +
  labs(x = "Year", y = "Average Data Value", title = "Average Data Value by State (Excellent Responses)") +
  theme_minimal()
```

*   The above plot gives the average data value from 2002 to 2010 across the states in the US, in which only the observations with `Excellent` responses were kept. 

3.    *Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.*

Filter the qualified data.
```{r}
ny_data = brfss_clean |>
  filter(locationabbr == "NY") |>
  filter(year %in% c(2006, 2010)) 
  
```

Make the two-panel plot.

```{r}
ggplot(ny_data, aes(x = year, y = data_value, group = year)) +
  geom_boxplot(fill = "steelblue", color = "black") +
  facet_grid(. ~ response) +
  labs(x = "Year", y = "Data Value", title = "Distribution of Data Value by Response (NY State)") +
  theme_minimal()
```

*   The boxplot compares the distribution of `data_value` between 2006 and 2010 in terms of different `response` level in NY state. 


## Problem 3

This problem aims to observe the accelerometer data collected on 250 participants in the NHANES study. 

First, we load the demographic and accelerometer data of the 250 participants, and tidy them accordingly. 

```{r}
acl_df = read_csv("data/nhanes_accel.csv",show_col_types = FALSE) 

education_mapping <- c("Less than high school", "High school equivalent", "More than high school")
sex_mapping <- c("male", "female")

mims_df = read_csv("data/nhanes_covar.csv", skip = 4,show_col_types = FALSE) |>
  filter(age >= 21) |>
  na.omit()|>
  merge(acl_df) |>
  mutate(
    education = factor(education_mapping[education], levels = education_mapping),
    sex = factor(sex_mapping[sex], levels = sex_mapping)
  )
```

Then, we produce a table about the number of men and women in each education category.

```{r}
sex_education = mims_df |>
  group_by(education, sex) |>
  summarize(count = n()) |>
  pivot_wider(names_from = sex, values_from = count)

knitr::kable(sex_education)
```

Visualize the age distribution in each category.

```{r}
ggplot(mims_df, aes(x = sex, y = age,fill = sex)) +
  geom_boxplot() +
  facet_grid(~education) +
  labs(x = "Sex", y = "Age", title = "Age Distribution by Education and Sex") +
  theme_minimal()
```

The boxplot shows the age distribution by education and sex. As we can see from the graph, the age distribution between male and female in "Less than high school" group and "More than high school" group are similar. The biggest difference between the distribution pattern appears in the "High school equivalent" group, with female generally has a older age.

Let's focus on the total activity of each participants.

```{r}
total_activity_df <- mims_df |>
  rowwise() |>
  mutate(total_activity = sum(c_across(starts_with("min"))))
```

Plot the total activity against age, with men and women in different panel for each education level.

```{r}
ggplot(total_activity_df, aes(x = age, y = total_activity, color = sex)) +
  geom_point() +             
  geom_smooth( se = FALSE) +  
  facet_wrap(~education) +    
  labs(x = "Age", y = "Total Activity", title = "Total Activity vs. Age by Gender and Education Level") +
  theme_minimal()
```
As we can see from the plot, in each education level, male and female show different trend. 

*   For "Less than high school" group, both male and female show a peak in the total activity in around age 60; for "High school equivalent" group, the summit is around age 40; for "More than high school" group, male shows a peak at age 45 while female shows an insginificant peak at age 60.

*   Generally, in the "Less than high school" group, male shows a higher total activity rate; in the other two groups, female shows a higher total activity rate. 

Lastly, we focus on the 24-hour activity time courses for each education level and different sex. We make a plot accordingly. 

```{r}
activity_minute <- mims_df %>%
  pivot_longer(cols = starts_with("min"), names_to = "minute", values_to = "activity_level") |>
  mutate(minute = gsub("min", "", minute))

ggplot(activity_minute, aes(x = as.numeric(minute), y = activity_level, color = sex)) +
  geom_point(size = .3, alpha = .1) +
  geom_smooth( se = FALSE) +
  facet_wrap(~education, ncol = 1, scales = "free") +  
  labs(x = "Minute of the Day", y = "Activity Level", title = "Activity Time Course by Education Level and Gender") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 60, size = 3))

```

The above plot shows the accelerometer value through out the day in different education levels and sex. In the smooth line, we can see no big differences between the distribution of the accelerometer value in the two sex. Also, the ups and downs appears in the similar minutes in the a day (up at the 500th minute and down at the 250th minute), and the general activity level is quite similar across different education level (under 25). 






