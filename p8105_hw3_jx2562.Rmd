---
title: "p8105_hx3_jx562"
author: "Jingyi"
date: "2023-10-11"
output: github_document
---

```{r, message=F}
library(tidyverse)
```


## Problem 1

This problem aims to explore `instacart` data.

First, we loaded the data `instacart`.

```{r}
library(p8105.datasets)
data("instacart")
```

The data `instacart` has features as described below.

*   The data has `r ncol(instacart)` observations and `r nrow(instacart)` variables.
*   The data has variables named `r colnames(instacart)`.
*   There are `r length(unique(instacart$aisle))` diffrent aisles, whose `aisle_id` range from `r min(instacart$aisle_id)` to `r max(instacart$aisle_id)`. 
*   There are `r length(unique(instacart$product_name))` different product.
*   Overall, the `order_number` ranges from `r min(instacart$order_number)` to `r max(instacart$order_number)` with a mean `r round(mean(instacart$order_number), 2)`
*   An example of the observations of the data is demonstrated below.

```{r}
head(instacart, 3)
```

Then, we need to answer a few questions regarding the dataset.

1.    *How many aisles are there, and which aisles are the most items ordered from?*

*   There are `r length(unique(instacart$aisle))` different aisles. 

```{r}
aisle_order = instacart |>
  group_by(aisle) |>
  summarize(order_number_aisle = sum(order_number)) |>
  arrange(desc(order_number_aisle))
```
*   The aisle where most items are ordered from and the number of order are `r head(aisle_order, 1)`.

2.    *Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. *

```{r}
aisle_order_10000 = instacart |>
  group_by(aisle_id) |>
  summarize(order_number_aisle = sum(order_number)) |>
  filter(order_number_aisle > 10000) |>
  mutate(aisle_id = as.factor(aisle_id))

ggplot(aisle_order_10000, aes(x = aisle_id, y = order_number_aisle)) +
  geom_bar(stat = "identity", fill = "steelblue",  width = 0.5) +
  labs(x = "Aisle ID", y = "Total Order Count", title = "Total Orders by Aisle (Aisles with > 10,000 Orders)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 60, size = 6)) +
  scale_x_discrete(breaks = aisle_order_10000$aisle_id[1:nrow(aisle_order_10000) %% 3 == 0])
```
*   Given the aisle id, we can look up to the exact aisle name. There are `r nrow(aisle_order_10000)` out of `r nrow(aisle_order)` which has an order number larger than 10000. The aisles with top 5 total order number count are `r aisle_order$aisle[1:5]`.

3.    *Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.*

```{r}
aisle_times = instacart |>
  group_by(aisle) |>
  summarize(order_times = n()) |>
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) 
knitr::kable(aisle_times)
```

*   The number of times ordered is obtained by counting the number of order in each aisle for the three types of aisles. It shows that `packaged vegetables fruits` has the most order times.

4. *Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.*


```{r, warning=F}
product_hour = instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_order_hour = round(mean(order_hour_of_day),2)) |>
  pivot_wider(names_from = order_dow, values_from = mean_order_hour) 
colnames(product_hour)[2:8] = c("Sun","Mon","Tue","Wed","Thu","Fri","Sat")
knitr::kable(product_hour)
```
*   The table shows the mean hour of the day at which the two product are ordered in terms of each day of the week. 


## Problem 2

This problem aims to explore `BRFSS` data.

First, we loaded the data `BRFSS`.

```{r}
library(p8105.datasets)
data("brfss_smart2010")
```

Do some data cleaning regarding to the dataset.

```{r}
brfss_clean = brfss_smart2010 |>
  janitor::clean_names() |>
  filter(topic == "Overall Health") |>
  filter(response %in% c("Poor","Fair","Good", "Very good","Excellent")) |>
  mutate(response = factor(response, levels = c("Poor","Fair","Good", "Very good","Excellent"), ordered = T))
```

Then, we are going to answer some questions regarding to the data set.

1.    *In 2002, which states were observed at 7 or more locations? What about in 2010?*

```{r, warning=F}
state_obs_2002 = brfss_clean |>
  filter(year == 2002) |>
  group_by(locationabbr, locationdesc) |>
  summarise(locationdesc_count = n()) |>
  group_by(locationabbr) |>
  summarise(location_in_state = n())

state_obs_2010 = brfss_clean |>
  filter(year == 2010) |>
  group_by(locationabbr, locationdesc) |>
  summarise(locationdesc_count = n()) |>
  group_by(locationabbr) |>
  summarise(location_in_state = n())
```

*   The above datasets give the count number of different locations where a state was observed in 2002 or 2010. In 2002, `r state_obs_2002 |> filter(location_in_state >= 7) |> pull(locationabbr)` states were observed at 7 or more locations. In 2010, `r state_obs_2010 |> filter(location_in_state >= 7) |> pull(locationabbr)` states were observed at 7 or more locations.

2.    *Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state.*

```{r}
state_value = brfss_clean |>
  filter(response == "Excellent") |>
  group_by(year, locationabbr) |>
  summarise(mean_value = mean(data_value)) |>
  select(state = locationabbr, everything())
```

Make the "spaghetti" plot.

```{r, warning=F}
ggplot(state_value, aes(x = year, y = mean_value, color = state, group = state)) +
  geom_line() +
  labs(x = "Year", y = "Average Data Value", title = "Average Data Value by State (Excellent Responses)") +
  theme_minimal()
```

*   The above plot gives the average data value from 2002 to 2010 across the states in the US, in which only the observations with `Excellent` responses were kept. 



